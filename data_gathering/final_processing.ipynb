{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An outline of the ultimate data processing to create usable master dataframes from which models can be easily built. As with other steps in this process, I did not run this at scale out of a notebook like, rather I have a .py file that I ran at the terminal, this notebook is solely for demonstration purposes. Some of these steps take a while to run and performing out of a notebook like this is inefficient: it made more sense to do the processing, save down the results as CSVs and then load those into a seperate notebook to visualize and build models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import datetime\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, and easiest step was to read in previously saved down stock info. The stock api I used was simple and quick enough that I could have called newly updated stock values on the fly without really any loss of speed, but I already had saved down all the historical stock data locally.\n",
    "\n",
    "I altered this to function later on to bring in empty columns (or columns filled with zeros) to correspond with the sentiment values from the NYT and twitter - the logic of this will become clear later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stock_formatter_lite(stock_ticker):\n",
    "    #takes in the stock ticker, since all csvs follow same naming conventions\n",
    "    stock_df = pd.read_csv(f'stock_data/{stock_ticker}.csv')\n",
    "    stock_df['Unnamed: 0'] = pd.to_datetime(stock_df['Unnamed: 0'])\n",
    "    stock_df.set_index('Unnamed: 0',inplace=True)\n",
    "    # And here are six columns which will later be filled with sentiment values\n",
    "    stock_df['nyt_compound'] = [0]*len(stock_df)\n",
    "    stock_df['nyt_pos'] = [0]*len(stock_df)\n",
    "    stock_df['nyt_neg'] = [0]*len(stock_df)\n",
    "    stock_df['twitter_compound'] = [0]*len(stock_df)\n",
    "    stock_df['twitter_pos'] = [0]*len(stock_df)\n",
    "    stock_df['twitter_neg'] = [0]*len(stock_df)\n",
    "    return stock_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "tesla_stock = stock_formatter_lite('TSLA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1. open</th>\n",
       "      <th>2. high</th>\n",
       "      <th>3. low</th>\n",
       "      <th>4. close</th>\n",
       "      <th>5. volume</th>\n",
       "      <th>nyt_compound</th>\n",
       "      <th>nyt_pos</th>\n",
       "      <th>nyt_neg</th>\n",
       "      <th>twitter_compound</th>\n",
       "      <th>twitter_pos</th>\n",
       "      <th>twitter_neg</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-07-06</th>\n",
       "      <td>20.00</td>\n",
       "      <td>20.0000</td>\n",
       "      <td>15.83</td>\n",
       "      <td>16.11</td>\n",
       "      <td>6866900</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-07-02</th>\n",
       "      <td>23.00</td>\n",
       "      <td>23.1000</td>\n",
       "      <td>18.71</td>\n",
       "      <td>19.20</td>\n",
       "      <td>5139800</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-07-01</th>\n",
       "      <td>25.00</td>\n",
       "      <td>25.9200</td>\n",
       "      <td>20.27</td>\n",
       "      <td>21.96</td>\n",
       "      <td>8218800</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-06-30</th>\n",
       "      <td>25.79</td>\n",
       "      <td>30.4192</td>\n",
       "      <td>23.30</td>\n",
       "      <td>23.83</td>\n",
       "      <td>17187100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-06-29</th>\n",
       "      <td>19.00</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>17.54</td>\n",
       "      <td>23.89</td>\n",
       "      <td>18766300</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            1. open  2. high  3. low  4. close  5. volume  nyt_compound  \\\n",
       "Unnamed: 0                                                                \n",
       "2010-07-06    20.00  20.0000   15.83     16.11    6866900             0   \n",
       "2010-07-02    23.00  23.1000   18.71     19.20    5139800             0   \n",
       "2010-07-01    25.00  25.9200   20.27     21.96    8218800             0   \n",
       "2010-06-30    25.79  30.4192   23.30     23.83   17187100             0   \n",
       "2010-06-29    19.00  25.0000   17.54     23.89   18766300             0   \n",
       "\n",
       "            nyt_pos  nyt_neg  twitter_compound  twitter_pos  twitter_neg  \n",
       "Unnamed: 0                                                                \n",
       "2010-07-06        0        0                 0            0            0  \n",
       "2010-07-02        0        0                 0            0            0  \n",
       "2010-07-01        0        0                 0            0            0  \n",
       "2010-06-30        0        0                 0            0            0  \n",
       "2010-06-29        0        0                 0            0            0  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tesla_stock.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now to create dataframes with new york times sentiment data. First, the dataframe cleaning function and term counting helper function I previously used in the nyt exploration notebook.\n",
    "\n",
    "Next comes a function to take in a series of file names and compile a master dataframe from them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def term_counter(string, word):\n",
    "    tokens = nltk.word_tokenize(string)\n",
    "    return nltk.FreqDist(word.lower() for word in tokens)[word]\n",
    "\n",
    "def dataframe_cleaner(df, term, sensitivity):\n",
    "    indexes_to_drop = []\n",
    "    for n in range(0,len(df)):\n",
    "        try:\n",
    "            if term_counter(df.iloc[n]['text'],term) < sensitivity:\n",
    "                indexes_to_drop.append(n)\n",
    "        except:\n",
    "            indexes_to_drop.append(n)\n",
    "    df.drop(df.index[indexes_to_drop],axis=0,inplace=True)\n",
    "    df['compound'] = [sid.polarity_scores(text)['compound'] for text in df['text']]\n",
    "    df['neg'] = [sid.polarity_scores(text)['neg'] for text in df['text']]\n",
    "    df['pos'] = [sid.polarity_scores(text)['pos'] for text in df['text']]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nyt_sentiment(sentiment_files, company_name, sensitivity):\n",
    "    dataframes=[]\n",
    "    for file in sentiment_files:\n",
    "        df = pd.read_csv(f'nyt_text/{file}.csv')\n",
    "        df = dataframe_cleaner(df, company_name, sensitivity)\n",
    "        dataframes.append(df)\n",
    "    master_df = pd.concat(dataframes)\n",
    "    #Also, making the dataframe indexed to the date, properly formatted as datetime\n",
    "    master_df['date'] = pd.to_datetime(master_df['date']) \n",
    "    #Occasionally there may be more than one nyt article on a given topic in a given day\n",
    "    #I simply average the sentiment values across them in that instance\n",
    "    master_df = master_df.groupby('date').mean()\n",
    "    master_df.drop('Unnamed: 0',axis=1,inplace=True)\n",
    "    return master_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = ['tesla_2016','tesla_2017','tesla_2018']\n",
    "tesla_nyt = nyt_sentiment(files ,'tesla', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>compound</th>\n",
       "      <th>neg</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-14</th>\n",
       "      <td>0.96750</td>\n",
       "      <td>0.0520</td>\n",
       "      <td>0.079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-17</th>\n",
       "      <td>0.99140</td>\n",
       "      <td>0.0260</td>\n",
       "      <td>0.072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-02</th>\n",
       "      <td>-0.99420</td>\n",
       "      <td>0.1200</td>\n",
       "      <td>0.044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-01</th>\n",
       "      <td>0.97015</td>\n",
       "      <td>0.0195</td>\n",
       "      <td>0.064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-04</th>\n",
       "      <td>0.99740</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>0.108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            compound     neg    pos\n",
       "date                               \n",
       "2016-01-14   0.96750  0.0520  0.079\n",
       "2016-01-17   0.99140  0.0260  0.072\n",
       "2016-03-02  -0.99420  0.1200  0.044\n",
       "2016-04-01   0.97015  0.0195  0.064\n",
       "2016-04-04   0.99740  0.0500  0.108"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tesla_nyt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now something similar with twitter. Here's a function which takes in the file names and returns a master dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def twitter_sentiment(sentiment_files):\n",
    "    dataframes = []\n",
    "    for file in sentiment_files:\n",
    "        df = pd.read_csv(f'twitter/{file}.csv')\n",
    "        df.drop('Unnamed: 0',axis=1,inplace=True)\n",
    "        dataframes.append(df)\n",
    "    master_df = pd.concat(dataframes)\n",
    "    master_df['date'] = pd.to_datetime(master_df['date'])\n",
    "    master_df.set_index('date', inplace=True)\n",
    "    return master_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neg</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-01</th>\n",
       "      <td>0.054</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.9684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-02</th>\n",
       "      <td>0.061</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.7316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-03</th>\n",
       "      <td>0.044</td>\n",
       "      <td>0.016</td>\n",
       "      <td>-0.4696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-04</th>\n",
       "      <td>0.034</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.9878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-05</th>\n",
       "      <td>0.020</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.9983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              neg    pos  compound\n",
       "date                              \n",
       "2016-01-01  0.054  0.128    0.9684\n",
       "2016-01-02  0.061  0.081    0.7316\n",
       "2016-01-03  0.044  0.016   -0.4696\n",
       "2016-01-04  0.034  0.087    0.9878\n",
       "2016-01-05  0.020  0.169    0.9983"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = ['Tesla_twitter_sentiment_2016','Tesla_twitter_sentiment_2017','Tesla_twitter_sentiment_2018']\n",
    "tesla_twitter = twitter_sentiment(files)\n",
    "tesla_twitter.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now to the real challenge, combining these dataframes into a master in a way that overcame a couple of date issues and gave you something workable.\n",
    "\n",
    "The biggest issue here was that the dates didn't really align between the three dataframes:\n",
    "1. Stock data is only avalaible for days the market is open (obvioiusly): no weekends ore holidays in the stock dataframe.\n",
    "2. NYT sentiment is only available on days when there happened to be at least one article (again, obviously). Some companies had articles about them more often than others.\n",
    "3. Twitter sentiment comes almost every day a year (there were only ever a handful of days without data out of the whole range)\n",
    "\n",
    "How do we handle the mismatch in dates. The first key point is that we can't actually resample the stock data to be daily - it only really makes sense to talk about the price movement between days the market is open. So, my goal is clearly to pull the sentiment values from the other data frames into the stock one. The other key thing to note is that there's a lot of sentiment data coming on days when the market isn't open - plenty of articles are published on the weekends and twitter never sleeps. I clearly want to caputre this sentiment somehow.\n",
    "\n",
    "My function here to clean up and create the master dataframe handles this by averaging all of the sentiment values from the off-days together. So, my model is going to, say, try to predict price movement starting on Friday from the sentiment on Thursday. For Monday, which is preceded by days the market is closed, we'll be using the averaged sentiment values from Friday through Sunday. Since days the market is closed come at semi-irregular intervals (due to holidays) the function has to go through a little loop to find out exactly how many days need to be averaged together in any given case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Little helper function that simply returns the amount of price movement between two days\n",
    "def price_change(stock_df,index, n_days):\n",
    "    date = stock_df.index[index]\n",
    "    date_str = str(date)[:10]\n",
    "    future = str(stock_df.index[index-n_days])[:10]\n",
    "    initial_price = stock_df.loc[date_str,'4. close'][0]\n",
    "    later_price = stock_df.loc[future,'4. close'][0]\n",
    "    return (later_price/initial_price) -1\n",
    "\n",
    "def fill_out_sentiments(stock_df,nyt_df,twitter_df):\n",
    "    # stock csvs have data going back to 2010, so starting from 2016\n",
    "    stock_df = stock_df[:'2016']\n",
    "    for date in stock_df.index[1:]:\n",
    "        print(date) #so I can keep track when it runs in terminal\n",
    "        #first check if the following day was also a market open day\n",
    "        #if so, values can be pulled directly in\n",
    "        if date + datetime.timedelta(1) in stock_df.index:\n",
    "            date_str = str(date)[:10] #pandas indexing requires the string, not the timestamp\n",
    "            if date_str in nyt_df.index:\n",
    "                stock_df.loc[date_str,'nyt_compound'] = nyt_df.loc[date_str,'compound']\n",
    "                stock_df.loc[date_str,'nyt_pos'] = nyt_df.loc[date_str,'pos']\n",
    "                stock_df.loc[date_str,'nyt_neg'] = nyt_df.loc[date_str,'neg']\n",
    "            if date_str in twitter_df.index:\n",
    "                stock_df.loc[date_str,'twitter_compound'] = twitter_df.loc[date_str,'compound']\n",
    "                stock_df.loc[date_str,'twitter_pos'] = twitter_df.loc[date_str,'pos']\n",
    "                stock_df.loc[date_str,'twitter_neg'] = twitter_df.loc[date_str,'neg']\n",
    "        #Now, if the market was closed the following day, when was the next day the market was open?\n",
    "        else:\n",
    "            n = 1\n",
    "            while date + datetime.timedelta(n) not in stock_df.index:\n",
    "                n+=1\n",
    "            #n is now the number of days until the next open day\n",
    "            span_end = str(date + datetime.timedelta(n))[:10] #now we have a range of days to check\n",
    "            date_str = str(date)[:10]\n",
    "            #And we're going to average all the values from days in that range\n",
    "            stock_df.loc[date_str,'nyt_compound'] = nyt_df.loc[date_str:span_end,'compound'].mean()\n",
    "            stock_df.loc[date_str,'nyt_pos'] = nyt_df.loc[date_str:span_end,'pos'].mean()\n",
    "            stock_df.loc[date_str,'nyt_neg'] = nyt_df.loc[date_str:span_end,'neg'].mean()\n",
    "            stock_df.loc[date_str,'twitter_compound'] = twitter_df.loc[date_str:span_end,'compound'].mean()\n",
    "            stock_df.loc[date_str,'twitter_pos'] = twitter_df.loc[date_str:span_end,'pos'].mean()\n",
    "            stock_df.loc[date_str,'twitter_neg'] = twitter_df.loc[date_str:span_end,'neg'].mean()\n",
    "        #This pulls in the occasional NaN for days with no sentiment, fill those with 0\n",
    "        stock_df.fillna(0,inplace=True)\n",
    "        stock_df.index.rename('date',inplace=True)\n",
    "        #Also adding in the price change columns here\n",
    "        stock_df['day_change'] = [0]+[price_change(stock_df,n,1) for n in range(1,len(stock_df))]\n",
    "        stock_df['three_day'] = 3*[0]+[price_change(stock_df,n,1) for n in range(3,len(stock_df))]\n",
    "        stock_df['week_change'] = 5*[0]+[price_change(stock_df,n,1) for n in range(5,len(stock_df))]\n",
    "    return stock_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-07-18 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-07-17 00:00:00\n",
      "2019-07-16 00:00:00\n",
      "2019-07-15 00:00:00\n",
      "2019-07-12 00:00:00\n",
      "2019-07-11 00:00:00\n",
      "2019-07-10 00:00:00\n",
      "2019-07-09 00:00:00\n",
      "2019-07-08 00:00:00\n",
      "2019-07-05 00:00:00\n",
      "2019-07-03 00:00:00\n",
      "2019-07-02 00:00:00\n",
      "2019-07-01 00:00:00\n",
      "2019-06-28 00:00:00\n",
      "2019-06-27 00:00:00\n",
      "2019-06-26 00:00:00\n",
      "2019-06-25 00:00:00\n",
      "2019-06-24 00:00:00\n",
      "2019-06-21 00:00:00\n",
      "2019-06-20 00:00:00\n",
      "2019-06-19 00:00:00\n",
      "2019-06-18 00:00:00\n",
      "2019-06-17 00:00:00\n",
      "2019-06-14 00:00:00\n",
      "2019-06-13 00:00:00\n",
      "2019-06-12 00:00:00\n",
      "2019-06-11 00:00:00\n",
      "2019-06-10 00:00:00\n",
      "2019-06-07 00:00:00\n",
      "2019-06-06 00:00:00\n",
      "2019-06-05 00:00:00\n",
      "2019-06-04 00:00:00\n",
      "2019-06-03 00:00:00\n",
      "2019-05-31 00:00:00\n",
      "2019-05-30 00:00:00\n",
      "2019-05-29 00:00:00\n",
      "2019-05-28 00:00:00\n",
      "2019-05-24 00:00:00\n",
      "2019-05-23 00:00:00\n",
      "2019-05-22 00:00:00\n",
      "2019-05-21 00:00:00\n",
      "2019-05-20 00:00:00\n",
      "2019-05-17 00:00:00\n",
      "2019-05-16 00:00:00\n",
      "2019-05-15 00:00:00\n",
      "2019-05-14 00:00:00\n",
      "2019-05-13 00:00:00\n",
      "2019-05-10 00:00:00\n",
      "2019-05-09 00:00:00\n",
      "2019-05-08 00:00:00\n",
      "2019-05-07 00:00:00\n",
      "2019-05-06 00:00:00\n",
      "2019-05-03 00:00:00\n",
      "2019-05-02 00:00:00\n",
      "2019-05-01 00:00:00\n",
      "2019-04-30 00:00:00\n",
      "2019-04-29 00:00:00\n",
      "2019-04-26 00:00:00\n",
      "2019-04-25 00:00:00\n",
      "2019-04-24 00:00:00\n",
      "2019-04-23 00:00:00\n",
      "2019-04-22 00:00:00\n",
      "2019-04-18 00:00:00\n",
      "2019-04-17 00:00:00\n",
      "2019-04-16 00:00:00\n",
      "2019-04-15 00:00:00\n",
      "2019-04-12 00:00:00\n",
      "2019-04-11 00:00:00\n",
      "2019-04-10 00:00:00\n",
      "2019-04-09 00:00:00\n",
      "2019-04-08 00:00:00\n",
      "2019-04-05 00:00:00\n",
      "2019-04-04 00:00:00\n",
      "2019-04-03 00:00:00\n",
      "2019-04-02 00:00:00\n",
      "2019-04-01 00:00:00\n",
      "2019-03-29 00:00:00\n",
      "2019-03-28 00:00:00\n",
      "2019-03-27 00:00:00\n",
      "2019-03-26 00:00:00\n",
      "2019-03-25 00:00:00\n",
      "2019-03-22 00:00:00\n",
      "2019-03-21 00:00:00\n",
      "2019-03-20 00:00:00\n",
      "2019-03-19 00:00:00\n",
      "2019-03-18 00:00:00\n",
      "2019-03-15 00:00:00\n",
      "2019-03-14 00:00:00\n",
      "2019-03-13 00:00:00\n",
      "2019-03-12 00:00:00\n",
      "2019-03-11 00:00:00\n",
      "2019-03-08 00:00:00\n",
      "2019-03-07 00:00:00\n",
      "2019-03-06 00:00:00\n",
      "2019-03-05 00:00:00\n",
      "2019-03-04 00:00:00\n",
      "2019-03-01 00:00:00\n",
      "2019-02-28 00:00:00\n",
      "2019-02-27 00:00:00\n",
      "2019-02-26 00:00:00\n",
      "2019-02-25 00:00:00\n",
      "2019-02-22 00:00:00\n",
      "2019-02-21 00:00:00\n",
      "2019-02-20 00:00:00\n",
      "2019-02-19 00:00:00\n",
      "2019-02-15 00:00:00\n",
      "2019-02-14 00:00:00\n",
      "2019-02-13 00:00:00\n",
      "2019-02-12 00:00:00\n",
      "2019-02-11 00:00:00\n",
      "2019-02-08 00:00:00\n",
      "2019-02-07 00:00:00\n",
      "2019-02-06 00:00:00\n",
      "2019-02-05 00:00:00\n",
      "2019-02-04 00:00:00\n",
      "2019-02-01 00:00:00\n",
      "2019-01-31 00:00:00\n",
      "2019-01-30 00:00:00\n",
      "2019-01-29 00:00:00\n",
      "2019-01-28 00:00:00\n",
      "2019-01-25 00:00:00\n",
      "2019-01-24 00:00:00\n",
      "2019-01-23 00:00:00\n",
      "2019-01-22 00:00:00\n",
      "2019-01-18 00:00:00\n",
      "2019-01-17 00:00:00\n",
      "2019-01-16 00:00:00\n",
      "2019-01-15 00:00:00\n",
      "2019-01-14 00:00:00\n",
      "2019-01-11 00:00:00\n",
      "2019-01-10 00:00:00\n",
      "2019-01-09 00:00:00\n",
      "2019-01-08 00:00:00\n",
      "2019-01-07 00:00:00\n",
      "2019-01-04 00:00:00\n",
      "2019-01-03 00:00:00\n",
      "2019-01-02 00:00:00\n",
      "2018-12-31 00:00:00\n",
      "2018-12-28 00:00:00\n",
      "2018-12-27 00:00:00\n",
      "2018-12-26 00:00:00\n",
      "2018-12-24 00:00:00\n",
      "2018-12-21 00:00:00\n",
      "2018-12-20 00:00:00\n",
      "2018-12-19 00:00:00\n",
      "2018-12-18 00:00:00\n",
      "2018-12-17 00:00:00\n",
      "2018-12-14 00:00:00\n",
      "2018-12-13 00:00:00\n",
      "2018-12-12 00:00:00\n",
      "2018-12-11 00:00:00\n",
      "2018-12-10 00:00:00\n",
      "2018-12-07 00:00:00\n",
      "2018-12-06 00:00:00\n",
      "2018-12-04 00:00:00\n",
      "2018-12-03 00:00:00\n",
      "2018-11-30 00:00:00\n",
      "2018-11-29 00:00:00\n",
      "2018-11-28 00:00:00\n",
      "2018-11-27 00:00:00\n",
      "2018-11-26 00:00:00\n",
      "2018-11-23 00:00:00\n",
      "2018-11-21 00:00:00\n",
      "2018-11-20 00:00:00\n",
      "2018-11-19 00:00:00\n",
      "2018-11-16 00:00:00\n",
      "2018-11-15 00:00:00\n",
      "2018-11-14 00:00:00\n",
      "2018-11-13 00:00:00\n",
      "2018-11-12 00:00:00\n",
      "2018-11-09 00:00:00\n",
      "2018-11-08 00:00:00\n",
      "2018-11-07 00:00:00\n",
      "2018-11-06 00:00:00\n",
      "2018-11-05 00:00:00\n",
      "2018-11-02 00:00:00\n",
      "2018-11-01 00:00:00\n",
      "2018-10-31 00:00:00\n",
      "2018-10-30 00:00:00\n",
      "2018-10-29 00:00:00\n",
      "2018-10-26 00:00:00\n",
      "2018-10-25 00:00:00\n",
      "2018-10-24 00:00:00\n",
      "2018-10-23 00:00:00\n",
      "2018-10-22 00:00:00\n",
      "2018-10-19 00:00:00\n",
      "2018-10-18 00:00:00\n",
      "2018-10-17 00:00:00\n",
      "2018-10-16 00:00:00\n",
      "2018-10-15 00:00:00\n",
      "2018-10-12 00:00:00\n",
      "2018-10-11 00:00:00\n",
      "2018-10-10 00:00:00\n",
      "2018-10-09 00:00:00\n",
      "2018-10-08 00:00:00\n",
      "2018-10-05 00:00:00\n",
      "2018-10-04 00:00:00\n",
      "2018-10-03 00:00:00\n",
      "2018-10-02 00:00:00\n",
      "2018-10-01 00:00:00\n",
      "2018-09-28 00:00:00\n",
      "2018-09-27 00:00:00\n",
      "2018-09-26 00:00:00\n",
      "2018-09-25 00:00:00\n",
      "2018-09-24 00:00:00\n",
      "2018-09-21 00:00:00\n",
      "2018-09-20 00:00:00\n",
      "2018-09-19 00:00:00\n",
      "2018-09-18 00:00:00\n",
      "2018-09-17 00:00:00\n",
      "2018-09-14 00:00:00\n",
      "2018-09-13 00:00:00\n",
      "2018-09-12 00:00:00\n",
      "2018-09-11 00:00:00\n",
      "2018-09-10 00:00:00\n",
      "2018-09-07 00:00:00\n",
      "2018-09-06 00:00:00\n",
      "2018-09-05 00:00:00\n",
      "2018-09-04 00:00:00\n",
      "2018-08-31 00:00:00\n",
      "2018-08-30 00:00:00\n",
      "2018-08-29 00:00:00\n",
      "2018-08-28 00:00:00\n",
      "2018-08-27 00:00:00\n",
      "2018-08-24 00:00:00\n",
      "2018-08-23 00:00:00\n",
      "2018-08-22 00:00:00\n",
      "2018-08-21 00:00:00\n",
      "2018-08-20 00:00:00\n",
      "2018-08-17 00:00:00\n",
      "2018-08-16 00:00:00\n",
      "2018-08-15 00:00:00\n",
      "2018-08-14 00:00:00\n",
      "2018-08-13 00:00:00\n",
      "2018-08-10 00:00:00\n",
      "2018-08-09 00:00:00\n",
      "2018-08-08 00:00:00\n",
      "2018-08-07 00:00:00\n",
      "2018-08-06 00:00:00\n",
      "2018-08-03 00:00:00\n",
      "2018-08-02 00:00:00\n",
      "2018-08-01 00:00:00\n",
      "2018-07-31 00:00:00\n",
      "2018-07-30 00:00:00\n",
      "2018-07-27 00:00:00\n",
      "2018-07-26 00:00:00\n",
      "2018-07-25 00:00:00\n",
      "2018-07-24 00:00:00\n",
      "2018-07-23 00:00:00\n",
      "2018-07-20 00:00:00\n",
      "2018-07-19 00:00:00\n",
      "2018-07-18 00:00:00\n",
      "2018-07-17 00:00:00\n",
      "2018-07-16 00:00:00\n",
      "2018-07-13 00:00:00\n",
      "2018-07-12 00:00:00\n",
      "2018-07-11 00:00:00\n",
      "2018-07-10 00:00:00\n",
      "2018-07-09 00:00:00\n",
      "2018-07-06 00:00:00\n",
      "2018-07-05 00:00:00\n",
      "2018-07-03 00:00:00\n",
      "2018-07-02 00:00:00\n",
      "2018-06-29 00:00:00\n",
      "2018-06-28 00:00:00\n",
      "2018-06-27 00:00:00\n",
      "2018-06-26 00:00:00\n",
      "2018-06-25 00:00:00\n",
      "2018-06-22 00:00:00\n",
      "2018-06-21 00:00:00\n",
      "2018-06-20 00:00:00\n",
      "2018-06-19 00:00:00\n",
      "2018-06-18 00:00:00\n",
      "2018-06-15 00:00:00\n",
      "2018-06-14 00:00:00\n",
      "2018-06-13 00:00:00\n",
      "2018-06-12 00:00:00\n",
      "2018-06-11 00:00:00\n",
      "2018-06-08 00:00:00\n",
      "2018-06-07 00:00:00\n",
      "2018-06-06 00:00:00\n",
      "2018-06-05 00:00:00\n",
      "2018-06-04 00:00:00\n",
      "2018-06-01 00:00:00\n",
      "2018-05-31 00:00:00\n",
      "2018-05-30 00:00:00\n",
      "2018-05-29 00:00:00\n",
      "2018-05-25 00:00:00\n",
      "2018-05-24 00:00:00\n",
      "2018-05-23 00:00:00\n",
      "2018-05-22 00:00:00\n",
      "2018-05-21 00:00:00\n",
      "2018-05-18 00:00:00\n",
      "2018-05-17 00:00:00\n",
      "2018-05-16 00:00:00\n",
      "2018-05-15 00:00:00\n",
      "2018-05-14 00:00:00\n",
      "2018-05-11 00:00:00\n",
      "2018-05-10 00:00:00\n",
      "2018-05-09 00:00:00\n",
      "2018-05-08 00:00:00\n",
      "2018-05-07 00:00:00\n",
      "2018-05-04 00:00:00\n",
      "2018-05-03 00:00:00\n",
      "2018-05-02 00:00:00\n",
      "2018-05-01 00:00:00\n",
      "2018-04-30 00:00:00\n",
      "2018-04-27 00:00:00\n",
      "2018-04-26 00:00:00\n",
      "2018-04-25 00:00:00\n",
      "2018-04-24 00:00:00\n",
      "2018-04-23 00:00:00\n",
      "2018-04-20 00:00:00\n",
      "2018-04-19 00:00:00\n",
      "2018-04-18 00:00:00\n",
      "2018-04-17 00:00:00\n",
      "2018-04-16 00:00:00\n",
      "2018-04-13 00:00:00\n",
      "2018-04-12 00:00:00\n",
      "2018-04-11 00:00:00\n",
      "2018-04-10 00:00:00\n",
      "2018-04-09 00:00:00\n",
      "2018-04-06 00:00:00\n",
      "2018-04-05 00:00:00\n",
      "2018-04-04 00:00:00\n",
      "2018-04-03 00:00:00\n",
      "2018-04-02 00:00:00\n",
      "2018-03-29 00:00:00\n",
      "2018-03-28 00:00:00\n",
      "2018-03-27 00:00:00\n",
      "2018-03-26 00:00:00\n",
      "2018-03-23 00:00:00\n",
      "2018-03-22 00:00:00\n",
      "2018-03-21 00:00:00\n",
      "2018-03-20 00:00:00\n",
      "2018-03-19 00:00:00\n",
      "2018-03-16 00:00:00\n",
      "2018-03-15 00:00:00\n",
      "2018-03-14 00:00:00\n",
      "2018-03-13 00:00:00\n",
      "2018-03-12 00:00:00\n",
      "2018-03-09 00:00:00\n",
      "2018-03-08 00:00:00\n",
      "2018-03-07 00:00:00\n",
      "2018-03-06 00:00:00\n",
      "2018-03-05 00:00:00\n",
      "2018-03-02 00:00:00\n",
      "2018-03-01 00:00:00\n",
      "2018-02-28 00:00:00\n",
      "2018-02-27 00:00:00\n",
      "2018-02-26 00:00:00\n",
      "2018-02-23 00:00:00\n",
      "2018-02-22 00:00:00\n",
      "2018-02-21 00:00:00\n",
      "2018-02-20 00:00:00\n",
      "2018-02-16 00:00:00\n",
      "2018-02-15 00:00:00\n",
      "2018-02-14 00:00:00\n",
      "2018-02-13 00:00:00\n",
      "2018-02-12 00:00:00\n",
      "2018-02-09 00:00:00\n",
      "2018-02-08 00:00:00\n",
      "2018-02-07 00:00:00\n",
      "2018-02-06 00:00:00\n",
      "2018-02-05 00:00:00\n",
      "2018-02-02 00:00:00\n",
      "2018-02-01 00:00:00\n",
      "2018-01-31 00:00:00\n",
      "2018-01-30 00:00:00\n",
      "2018-01-29 00:00:00\n",
      "2018-01-26 00:00:00\n",
      "2018-01-25 00:00:00\n",
      "2018-01-24 00:00:00\n",
      "2018-01-23 00:00:00\n",
      "2018-01-22 00:00:00\n",
      "2018-01-19 00:00:00\n",
      "2018-01-18 00:00:00\n",
      "2018-01-17 00:00:00\n",
      "2018-01-16 00:00:00\n",
      "2018-01-12 00:00:00\n",
      "2018-01-11 00:00:00\n",
      "2018-01-10 00:00:00\n",
      "2018-01-09 00:00:00\n",
      "2018-01-08 00:00:00\n",
      "2018-01-05 00:00:00\n",
      "2018-01-04 00:00:00\n",
      "2018-01-03 00:00:00\n",
      "2018-01-02 00:00:00\n",
      "2017-12-29 00:00:00\n",
      "2017-12-28 00:00:00\n",
      "2017-12-27 00:00:00\n",
      "2017-12-26 00:00:00\n",
      "2017-12-22 00:00:00\n",
      "2017-12-21 00:00:00\n",
      "2017-12-20 00:00:00\n",
      "2017-12-19 00:00:00\n",
      "2017-12-18 00:00:00\n",
      "2017-12-15 00:00:00\n",
      "2017-12-14 00:00:00\n",
      "2017-12-13 00:00:00\n",
      "2017-12-12 00:00:00\n",
      "2017-12-11 00:00:00\n",
      "2017-12-08 00:00:00\n",
      "2017-12-07 00:00:00\n",
      "2017-12-06 00:00:00\n",
      "2017-12-05 00:00:00\n",
      "2017-12-04 00:00:00\n",
      "2017-12-01 00:00:00\n",
      "2017-11-30 00:00:00\n",
      "2017-11-29 00:00:00\n",
      "2017-11-28 00:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-11-27 00:00:00\n",
      "2017-11-24 00:00:00\n",
      "2017-11-22 00:00:00\n",
      "2017-11-21 00:00:00\n",
      "2017-11-20 00:00:00\n",
      "2017-11-17 00:00:00\n",
      "2017-11-16 00:00:00\n",
      "2017-11-15 00:00:00\n",
      "2017-11-14 00:00:00\n",
      "2017-11-13 00:00:00\n",
      "2017-11-10 00:00:00\n",
      "2017-11-09 00:00:00\n",
      "2017-11-08 00:00:00\n",
      "2017-11-07 00:00:00\n",
      "2017-11-06 00:00:00\n",
      "2017-11-03 00:00:00\n",
      "2017-11-02 00:00:00\n",
      "2017-11-01 00:00:00\n",
      "2017-10-31 00:00:00\n",
      "2017-10-30 00:00:00\n",
      "2017-10-27 00:00:00\n",
      "2017-10-26 00:00:00\n",
      "2017-10-25 00:00:00\n",
      "2017-10-24 00:00:00\n",
      "2017-10-23 00:00:00\n",
      "2017-10-20 00:00:00\n",
      "2017-10-19 00:00:00\n",
      "2017-10-18 00:00:00\n",
      "2017-10-17 00:00:00\n",
      "2017-10-16 00:00:00\n",
      "2017-10-13 00:00:00\n",
      "2017-10-12 00:00:00\n",
      "2017-10-11 00:00:00\n",
      "2017-10-10 00:00:00\n",
      "2017-10-09 00:00:00\n",
      "2017-10-06 00:00:00\n",
      "2017-10-05 00:00:00\n",
      "2017-10-04 00:00:00\n",
      "2017-10-03 00:00:00\n",
      "2017-10-02 00:00:00\n",
      "2017-09-29 00:00:00\n",
      "2017-09-28 00:00:00\n",
      "2017-09-27 00:00:00\n",
      "2017-09-26 00:00:00\n",
      "2017-09-25 00:00:00\n",
      "2017-09-22 00:00:00\n",
      "2017-09-21 00:00:00\n",
      "2017-09-20 00:00:00\n",
      "2017-09-19 00:00:00\n",
      "2017-09-18 00:00:00\n",
      "2017-09-15 00:00:00\n",
      "2017-09-14 00:00:00\n",
      "2017-09-13 00:00:00\n",
      "2017-09-12 00:00:00\n",
      "2017-09-11 00:00:00\n",
      "2017-09-08 00:00:00\n",
      "2017-09-07 00:00:00\n",
      "2017-09-06 00:00:00\n",
      "2017-09-05 00:00:00\n",
      "2017-09-01 00:00:00\n",
      "2017-08-31 00:00:00\n",
      "2017-08-30 00:00:00\n",
      "2017-08-29 00:00:00\n",
      "2017-08-28 00:00:00\n",
      "2017-08-25 00:00:00\n",
      "2017-08-24 00:00:00\n",
      "2017-08-23 00:00:00\n",
      "2017-08-22 00:00:00\n",
      "2017-08-21 00:00:00\n",
      "2017-08-18 00:00:00\n",
      "2017-08-17 00:00:00\n",
      "2017-08-16 00:00:00\n",
      "2017-08-15 00:00:00\n",
      "2017-08-14 00:00:00\n",
      "2017-08-11 00:00:00\n",
      "2017-08-10 00:00:00\n",
      "2017-08-09 00:00:00\n",
      "2017-08-08 00:00:00\n",
      "2017-08-07 00:00:00\n",
      "2017-08-04 00:00:00\n",
      "2017-08-03 00:00:00\n",
      "2017-08-02 00:00:00\n",
      "2017-08-01 00:00:00\n",
      "2017-07-31 00:00:00\n",
      "2017-07-28 00:00:00\n",
      "2017-07-27 00:00:00\n",
      "2017-07-26 00:00:00\n",
      "2017-07-25 00:00:00\n",
      "2017-07-24 00:00:00\n",
      "2017-07-21 00:00:00\n",
      "2017-07-20 00:00:00\n",
      "2017-07-19 00:00:00\n",
      "2017-07-18 00:00:00\n",
      "2017-07-17 00:00:00\n",
      "2017-07-14 00:00:00\n",
      "2017-07-13 00:00:00\n",
      "2017-07-12 00:00:00\n",
      "2017-07-11 00:00:00\n",
      "2017-07-10 00:00:00\n",
      "2017-07-07 00:00:00\n",
      "2017-07-06 00:00:00\n",
      "2017-07-05 00:00:00\n",
      "2017-07-03 00:00:00\n",
      "2017-06-30 00:00:00\n",
      "2017-06-29 00:00:00\n",
      "2017-06-28 00:00:00\n",
      "2017-06-27 00:00:00\n",
      "2017-06-26 00:00:00\n",
      "2017-06-23 00:00:00\n",
      "2017-06-22 00:00:00\n",
      "2017-06-21 00:00:00\n",
      "2017-06-20 00:00:00\n",
      "2017-06-19 00:00:00\n",
      "2017-06-16 00:00:00\n",
      "2017-06-15 00:00:00\n",
      "2017-06-14 00:00:00\n",
      "2017-06-13 00:00:00\n",
      "2017-06-12 00:00:00\n",
      "2017-06-09 00:00:00\n",
      "2017-06-08 00:00:00\n",
      "2017-06-07 00:00:00\n",
      "2017-06-06 00:00:00\n",
      "2017-06-05 00:00:00\n",
      "2017-06-02 00:00:00\n",
      "2017-06-01 00:00:00\n",
      "2017-05-31 00:00:00\n",
      "2017-05-30 00:00:00\n",
      "2017-05-26 00:00:00\n",
      "2017-05-25 00:00:00\n",
      "2017-05-24 00:00:00\n",
      "2017-05-23 00:00:00\n",
      "2017-05-22 00:00:00\n",
      "2017-05-19 00:00:00\n",
      "2017-05-18 00:00:00\n",
      "2017-05-17 00:00:00\n",
      "2017-05-16 00:00:00\n",
      "2017-05-15 00:00:00\n",
      "2017-05-12 00:00:00\n",
      "2017-05-11 00:00:00\n",
      "2017-05-10 00:00:00\n",
      "2017-05-09 00:00:00\n",
      "2017-05-08 00:00:00\n",
      "2017-05-05 00:00:00\n",
      "2017-05-04 00:00:00\n",
      "2017-05-03 00:00:00\n",
      "2017-05-02 00:00:00\n",
      "2017-05-01 00:00:00\n",
      "2017-04-28 00:00:00\n",
      "2017-04-27 00:00:00\n",
      "2017-04-26 00:00:00\n",
      "2017-04-25 00:00:00\n",
      "2017-04-24 00:00:00\n",
      "2017-04-21 00:00:00\n",
      "2017-04-20 00:00:00\n",
      "2017-04-19 00:00:00\n",
      "2017-04-18 00:00:00\n",
      "2017-04-17 00:00:00\n",
      "2017-04-13 00:00:00\n",
      "2017-04-12 00:00:00\n",
      "2017-04-11 00:00:00\n",
      "2017-04-10 00:00:00\n",
      "2017-04-07 00:00:00\n",
      "2017-04-06 00:00:00\n",
      "2017-04-05 00:00:00\n",
      "2017-04-04 00:00:00\n",
      "2017-04-03 00:00:00\n",
      "2017-03-31 00:00:00\n",
      "2017-03-30 00:00:00\n",
      "2017-03-29 00:00:00\n",
      "2017-03-28 00:00:00\n",
      "2017-03-27 00:00:00\n",
      "2017-03-24 00:00:00\n",
      "2017-03-23 00:00:00\n",
      "2017-03-22 00:00:00\n",
      "2017-03-21 00:00:00\n",
      "2017-03-20 00:00:00\n",
      "2017-03-17 00:00:00\n",
      "2017-03-16 00:00:00\n",
      "2017-03-15 00:00:00\n",
      "2017-03-14 00:00:00\n",
      "2017-03-13 00:00:00\n",
      "2017-03-10 00:00:00\n",
      "2017-03-09 00:00:00\n",
      "2017-03-08 00:00:00\n",
      "2017-03-07 00:00:00\n",
      "2017-03-06 00:00:00\n",
      "2017-03-03 00:00:00\n",
      "2017-03-02 00:00:00\n",
      "2017-03-01 00:00:00\n",
      "2017-02-28 00:00:00\n",
      "2017-02-27 00:00:00\n",
      "2017-02-24 00:00:00\n",
      "2017-02-23 00:00:00\n",
      "2017-02-22 00:00:00\n",
      "2017-02-21 00:00:00\n",
      "2017-02-17 00:00:00\n",
      "2017-02-16 00:00:00\n",
      "2017-02-15 00:00:00\n",
      "2017-02-14 00:00:00\n",
      "2017-02-13 00:00:00\n",
      "2017-02-10 00:00:00\n",
      "2017-02-09 00:00:00\n",
      "2017-02-08 00:00:00\n",
      "2017-02-07 00:00:00\n",
      "2017-02-06 00:00:00\n",
      "2017-02-03 00:00:00\n",
      "2017-02-02 00:00:00\n",
      "2017-02-01 00:00:00\n",
      "2017-01-31 00:00:00\n",
      "2017-01-30 00:00:00\n",
      "2017-01-27 00:00:00\n",
      "2017-01-26 00:00:00\n",
      "2017-01-25 00:00:00\n",
      "2017-01-24 00:00:00\n",
      "2017-01-23 00:00:00\n",
      "2017-01-20 00:00:00\n",
      "2017-01-19 00:00:00\n",
      "2017-01-18 00:00:00\n",
      "2017-01-17 00:00:00\n",
      "2017-01-13 00:00:00\n",
      "2017-01-12 00:00:00\n",
      "2017-01-11 00:00:00\n",
      "2017-01-10 00:00:00\n",
      "2017-01-09 00:00:00\n",
      "2017-01-06 00:00:00\n",
      "2017-01-05 00:00:00\n",
      "2017-01-04 00:00:00\n",
      "2017-01-03 00:00:00\n",
      "2016-12-30 00:00:00\n",
      "2016-12-29 00:00:00\n",
      "2016-12-28 00:00:00\n",
      "2016-12-27 00:00:00\n",
      "2016-12-23 00:00:00\n",
      "2016-12-22 00:00:00\n",
      "2016-12-21 00:00:00\n",
      "2016-12-20 00:00:00\n",
      "2016-12-19 00:00:00\n",
      "2016-12-16 00:00:00\n",
      "2016-12-15 00:00:00\n",
      "2016-12-14 00:00:00\n",
      "2016-12-13 00:00:00\n",
      "2016-12-12 00:00:00\n",
      "2016-12-09 00:00:00\n",
      "2016-12-08 00:00:00\n",
      "2016-12-07 00:00:00\n",
      "2016-12-06 00:00:00\n",
      "2016-12-05 00:00:00\n",
      "2016-12-02 00:00:00\n",
      "2016-12-01 00:00:00\n",
      "2016-11-30 00:00:00\n",
      "2016-11-29 00:00:00\n",
      "2016-11-28 00:00:00\n",
      "2016-11-25 00:00:00\n",
      "2016-11-23 00:00:00\n",
      "2016-11-22 00:00:00\n",
      "2016-11-21 00:00:00\n",
      "2016-11-18 00:00:00\n",
      "2016-11-17 00:00:00\n",
      "2016-11-16 00:00:00\n",
      "2016-11-15 00:00:00\n",
      "2016-11-14 00:00:00\n",
      "2016-11-11 00:00:00\n",
      "2016-11-10 00:00:00\n",
      "2016-11-09 00:00:00\n",
      "2016-11-08 00:00:00\n",
      "2016-11-07 00:00:00\n",
      "2016-11-04 00:00:00\n",
      "2016-11-03 00:00:00\n",
      "2016-11-02 00:00:00\n",
      "2016-11-01 00:00:00\n",
      "2016-10-31 00:00:00\n",
      "2016-10-28 00:00:00\n",
      "2016-10-27 00:00:00\n",
      "2016-10-26 00:00:00\n",
      "2016-10-25 00:00:00\n",
      "2016-10-24 00:00:00\n",
      "2016-10-21 00:00:00\n",
      "2016-10-20 00:00:00\n",
      "2016-10-19 00:00:00\n",
      "2016-10-18 00:00:00\n",
      "2016-10-17 00:00:00\n",
      "2016-10-14 00:00:00\n",
      "2016-10-13 00:00:00\n",
      "2016-10-12 00:00:00\n",
      "2016-10-11 00:00:00\n",
      "2016-10-10 00:00:00\n",
      "2016-10-07 00:00:00\n",
      "2016-10-06 00:00:00\n",
      "2016-10-05 00:00:00\n",
      "2016-10-04 00:00:00\n",
      "2016-10-03 00:00:00\n",
      "2016-09-30 00:00:00\n",
      "2016-09-29 00:00:00\n",
      "2016-09-28 00:00:00\n",
      "2016-09-27 00:00:00\n",
      "2016-09-26 00:00:00\n",
      "2016-09-23 00:00:00\n",
      "2016-09-22 00:00:00\n",
      "2016-09-21 00:00:00\n",
      "2016-09-20 00:00:00\n",
      "2016-09-19 00:00:00\n",
      "2016-09-16 00:00:00\n",
      "2016-09-15 00:00:00\n",
      "2016-09-14 00:00:00\n",
      "2016-09-13 00:00:00\n",
      "2016-09-12 00:00:00\n",
      "2016-09-09 00:00:00\n",
      "2016-09-08 00:00:00\n",
      "2016-09-07 00:00:00\n",
      "2016-09-06 00:00:00\n",
      "2016-09-02 00:00:00\n",
      "2016-09-01 00:00:00\n",
      "2016-08-31 00:00:00\n",
      "2016-08-30 00:00:00\n",
      "2016-08-29 00:00:00\n",
      "2016-08-26 00:00:00\n",
      "2016-08-25 00:00:00\n",
      "2016-08-24 00:00:00\n",
      "2016-08-23 00:00:00\n",
      "2016-08-22 00:00:00\n",
      "2016-08-19 00:00:00\n",
      "2016-08-18 00:00:00\n",
      "2016-08-17 00:00:00\n",
      "2016-08-16 00:00:00\n",
      "2016-08-15 00:00:00\n",
      "2016-08-12 00:00:00\n",
      "2016-08-11 00:00:00\n",
      "2016-08-10 00:00:00\n",
      "2016-08-09 00:00:00\n",
      "2016-08-08 00:00:00\n",
      "2016-08-05 00:00:00\n",
      "2016-08-04 00:00:00\n",
      "2016-08-03 00:00:00\n",
      "2016-08-02 00:00:00\n",
      "2016-08-01 00:00:00\n",
      "2016-07-29 00:00:00\n",
      "2016-07-28 00:00:00\n",
      "2016-07-27 00:00:00\n",
      "2016-07-26 00:00:00\n",
      "2016-07-25 00:00:00\n",
      "2016-07-22 00:00:00\n",
      "2016-07-21 00:00:00\n",
      "2016-07-20 00:00:00\n",
      "2016-07-19 00:00:00\n",
      "2016-07-18 00:00:00\n",
      "2016-07-15 00:00:00\n",
      "2016-07-14 00:00:00\n",
      "2016-07-13 00:00:00\n",
      "2016-07-12 00:00:00\n",
      "2016-07-11 00:00:00\n",
      "2016-07-08 00:00:00\n",
      "2016-07-07 00:00:00\n",
      "2016-07-06 00:00:00\n",
      "2016-07-05 00:00:00\n",
      "2016-07-01 00:00:00\n",
      "2016-06-30 00:00:00\n",
      "2016-06-29 00:00:00\n",
      "2016-06-28 00:00:00\n",
      "2016-06-27 00:00:00\n",
      "2016-06-24 00:00:00\n",
      "2016-06-23 00:00:00\n",
      "2016-06-22 00:00:00\n",
      "2016-06-21 00:00:00\n",
      "2016-06-20 00:00:00\n",
      "2016-06-17 00:00:00\n",
      "2016-06-16 00:00:00\n",
      "2016-06-15 00:00:00\n",
      "2016-06-14 00:00:00\n",
      "2016-06-13 00:00:00\n",
      "2016-06-10 00:00:00\n",
      "2016-06-09 00:00:00\n",
      "2016-06-08 00:00:00\n",
      "2016-06-07 00:00:00\n",
      "2016-06-06 00:00:00\n",
      "2016-06-03 00:00:00\n",
      "2016-06-02 00:00:00\n",
      "2016-06-01 00:00:00\n",
      "2016-05-31 00:00:00\n",
      "2016-05-27 00:00:00\n",
      "2016-05-26 00:00:00\n",
      "2016-05-25 00:00:00\n",
      "2016-05-24 00:00:00\n",
      "2016-05-23 00:00:00\n",
      "2016-05-20 00:00:00\n",
      "2016-05-19 00:00:00\n",
      "2016-05-18 00:00:00\n",
      "2016-05-17 00:00:00\n",
      "2016-05-16 00:00:00\n",
      "2016-05-13 00:00:00\n",
      "2016-05-12 00:00:00\n",
      "2016-05-11 00:00:00\n",
      "2016-05-10 00:00:00\n",
      "2016-05-09 00:00:00\n",
      "2016-05-06 00:00:00\n",
      "2016-05-05 00:00:00\n",
      "2016-05-04 00:00:00\n",
      "2016-05-03 00:00:00\n",
      "2016-05-02 00:00:00\n",
      "2016-04-29 00:00:00\n",
      "2016-04-28 00:00:00\n",
      "2016-04-27 00:00:00\n",
      "2016-04-26 00:00:00\n",
      "2016-04-25 00:00:00\n",
      "2016-04-22 00:00:00\n",
      "2016-04-21 00:00:00\n",
      "2016-04-20 00:00:00\n",
      "2016-04-19 00:00:00\n",
      "2016-04-18 00:00:00\n",
      "2016-04-15 00:00:00\n",
      "2016-04-14 00:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-04-13 00:00:00\n",
      "2016-04-12 00:00:00\n",
      "2016-04-11 00:00:00\n",
      "2016-04-08 00:00:00\n",
      "2016-04-07 00:00:00\n",
      "2016-04-06 00:00:00\n",
      "2016-04-05 00:00:00\n",
      "2016-04-04 00:00:00\n",
      "2016-04-01 00:00:00\n",
      "2016-03-31 00:00:00\n",
      "2016-03-30 00:00:00\n",
      "2016-03-29 00:00:00\n",
      "2016-03-28 00:00:00\n",
      "2016-03-24 00:00:00\n",
      "2016-03-23 00:00:00\n",
      "2016-03-22 00:00:00\n",
      "2016-03-21 00:00:00\n",
      "2016-03-18 00:00:00\n",
      "2016-03-17 00:00:00\n",
      "2016-03-16 00:00:00\n",
      "2016-03-15 00:00:00\n",
      "2016-03-14 00:00:00\n",
      "2016-03-11 00:00:00\n",
      "2016-03-10 00:00:00\n",
      "2016-03-09 00:00:00\n",
      "2016-03-08 00:00:00\n",
      "2016-03-07 00:00:00\n",
      "2016-03-04 00:00:00\n",
      "2016-03-03 00:00:00\n",
      "2016-03-02 00:00:00\n",
      "2016-03-01 00:00:00\n",
      "2016-02-29 00:00:00\n",
      "2016-02-26 00:00:00\n",
      "2016-02-25 00:00:00\n",
      "2016-02-24 00:00:00\n",
      "2016-02-23 00:00:00\n",
      "2016-02-22 00:00:00\n",
      "2016-02-19 00:00:00\n",
      "2016-02-18 00:00:00\n",
      "2016-02-17 00:00:00\n",
      "2016-02-16 00:00:00\n",
      "2016-02-12 00:00:00\n",
      "2016-02-11 00:00:00\n",
      "2016-02-10 00:00:00\n",
      "2016-02-09 00:00:00\n",
      "2016-02-08 00:00:00\n",
      "2016-02-05 00:00:00\n",
      "2016-02-04 00:00:00\n",
      "2016-02-03 00:00:00\n",
      "2016-02-02 00:00:00\n",
      "2016-02-01 00:00:00\n",
      "2016-01-29 00:00:00\n",
      "2016-01-28 00:00:00\n",
      "2016-01-27 00:00:00\n",
      "2016-01-26 00:00:00\n",
      "2016-01-25 00:00:00\n",
      "2016-01-22 00:00:00\n",
      "2016-01-21 00:00:00\n",
      "2016-01-20 00:00:00\n",
      "2016-01-19 00:00:00\n",
      "2016-01-15 00:00:00\n",
      "2016-01-14 00:00:00\n",
      "2016-01-13 00:00:00\n",
      "2016-01-12 00:00:00\n",
      "2016-01-11 00:00:00\n",
      "2016-01-08 00:00:00\n",
      "2016-01-07 00:00:00\n",
      "2016-01-06 00:00:00\n",
      "2016-01-05 00:00:00\n",
      "2016-01-04 00:00:00\n"
     ]
    }
   ],
   "source": [
    "tesla_master = fill_out_sentiments(tesla_stock,tesla_nyt,tesla_twitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1. open</th>\n",
       "      <th>2. high</th>\n",
       "      <th>3. low</th>\n",
       "      <th>4. close</th>\n",
       "      <th>5. volume</th>\n",
       "      <th>nyt_compound</th>\n",
       "      <th>nyt_pos</th>\n",
       "      <th>nyt_neg</th>\n",
       "      <th>twitter_compound</th>\n",
       "      <th>twitter_pos</th>\n",
       "      <th>twitter_neg</th>\n",
       "      <th>day_change</th>\n",
       "      <th>three_day</th>\n",
       "      <th>week_change</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-15</th>\n",
       "      <td>198.97</td>\n",
       "      <td>205.0700</td>\n",
       "      <td>197.25</td>\n",
       "      <td>204.99</td>\n",
       "      <td>5578640</td>\n",
       "      <td>0.9914</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.988160</td>\n",
       "      <td>0.12720</td>\n",
       "      <td>0.01800</td>\n",
       "      <td>-0.001317</td>\n",
       "      <td>-0.001317</td>\n",
       "      <td>-0.001317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-14</th>\n",
       "      <td>202.21</td>\n",
       "      <td>210.0000</td>\n",
       "      <td>193.38</td>\n",
       "      <td>206.18</td>\n",
       "      <td>6490741</td>\n",
       "      <td>0.9675</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.995600</td>\n",
       "      <td>0.13300</td>\n",
       "      <td>0.02400</td>\n",
       "      <td>-0.005772</td>\n",
       "      <td>-0.005772</td>\n",
       "      <td>-0.005772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-13</th>\n",
       "      <td>212.01</td>\n",
       "      <td>212.6500</td>\n",
       "      <td>200.00</td>\n",
       "      <td>200.31</td>\n",
       "      <td>4126416</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.995800</td>\n",
       "      <td>0.12500</td>\n",
       "      <td>0.00900</td>\n",
       "      <td>0.029305</td>\n",
       "      <td>0.029305</td>\n",
       "      <td>0.029305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-12</th>\n",
       "      <td>211.60</td>\n",
       "      <td>213.7395</td>\n",
       "      <td>205.31</td>\n",
       "      <td>209.97</td>\n",
       "      <td>3091917</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.975900</td>\n",
       "      <td>0.06900</td>\n",
       "      <td>0.00900</td>\n",
       "      <td>-0.046007</td>\n",
       "      <td>-0.046007</td>\n",
       "      <td>-0.046007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-11</th>\n",
       "      <td>214.01</td>\n",
       "      <td>214.4500</td>\n",
       "      <td>203.00</td>\n",
       "      <td>207.85</td>\n",
       "      <td>4091422</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.996200</td>\n",
       "      <td>0.10800</td>\n",
       "      <td>0.02500</td>\n",
       "      <td>0.010200</td>\n",
       "      <td>0.010200</td>\n",
       "      <td>0.010200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-08</th>\n",
       "      <td>217.86</td>\n",
       "      <td>220.4400</td>\n",
       "      <td>210.77</td>\n",
       "      <td>211.00</td>\n",
       "      <td>3628058</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.993775</td>\n",
       "      <td>0.14575</td>\n",
       "      <td>0.03275</td>\n",
       "      <td>-0.014929</td>\n",
       "      <td>-0.014929</td>\n",
       "      <td>-0.014929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-07</th>\n",
       "      <td>214.19</td>\n",
       "      <td>218.4400</td>\n",
       "      <td>213.67</td>\n",
       "      <td>215.65</td>\n",
       "      <td>3554251</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.997700</td>\n",
       "      <td>0.17000</td>\n",
       "      <td>0.03400</td>\n",
       "      <td>-0.021563</td>\n",
       "      <td>-0.021563</td>\n",
       "      <td>-0.021563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-06</th>\n",
       "      <td>220.00</td>\n",
       "      <td>220.0500</td>\n",
       "      <td>215.98</td>\n",
       "      <td>219.04</td>\n",
       "      <td>3779128</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.996700</td>\n",
       "      <td>0.18200</td>\n",
       "      <td>0.01600</td>\n",
       "      <td>-0.015477</td>\n",
       "      <td>-0.015477</td>\n",
       "      <td>-0.015477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-05</th>\n",
       "      <td>226.36</td>\n",
       "      <td>226.8900</td>\n",
       "      <td>220.00</td>\n",
       "      <td>223.43</td>\n",
       "      <td>3186752</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.998300</td>\n",
       "      <td>0.16900</td>\n",
       "      <td>0.02000</td>\n",
       "      <td>-0.019648</td>\n",
       "      <td>-0.019648</td>\n",
       "      <td>-0.019648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-04</th>\n",
       "      <td>230.72</td>\n",
       "      <td>231.3800</td>\n",
       "      <td>219.00</td>\n",
       "      <td>223.41</td>\n",
       "      <td>6827146</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.987800</td>\n",
       "      <td>0.08700</td>\n",
       "      <td>0.03400</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.000090</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            1. open   2. high  3. low  4. close  5. volume  nyt_compound  \\\n",
       "date                                                                       \n",
       "2016-01-15   198.97  205.0700  197.25    204.99    5578640        0.9914   \n",
       "2016-01-14   202.21  210.0000  193.38    206.18    6490741        0.9675   \n",
       "2016-01-13   212.01  212.6500  200.00    200.31    4126416        0.0000   \n",
       "2016-01-12   211.60  213.7395  205.31    209.97    3091917        0.0000   \n",
       "2016-01-11   214.01  214.4500  203.00    207.85    4091422        0.0000   \n",
       "2016-01-08   217.86  220.4400  210.77    211.00    3628058        0.0000   \n",
       "2016-01-07   214.19  218.4400  213.67    215.65    3554251        0.0000   \n",
       "2016-01-06   220.00  220.0500  215.98    219.04    3779128        0.0000   \n",
       "2016-01-05   226.36  226.8900  220.00    223.43    3186752        0.0000   \n",
       "2016-01-04   230.72  231.3800  219.00    223.41    6827146        0.0000   \n",
       "\n",
       "            nyt_pos  nyt_neg  twitter_compound  twitter_pos  twitter_neg  \\\n",
       "date                                                                       \n",
       "2016-01-15    0.072    0.026          0.988160      0.12720      0.01800   \n",
       "2016-01-14    0.079    0.052          0.995600      0.13300      0.02400   \n",
       "2016-01-13    0.000    0.000          0.995800      0.12500      0.00900   \n",
       "2016-01-12    0.000    0.000          0.975900      0.06900      0.00900   \n",
       "2016-01-11    0.000    0.000          0.996200      0.10800      0.02500   \n",
       "2016-01-08    0.000    0.000          0.993775      0.14575      0.03275   \n",
       "2016-01-07    0.000    0.000          0.997700      0.17000      0.03400   \n",
       "2016-01-06    0.000    0.000          0.996700      0.18200      0.01600   \n",
       "2016-01-05    0.000    0.000          0.998300      0.16900      0.02000   \n",
       "2016-01-04    0.000    0.000          0.987800      0.08700      0.03400   \n",
       "\n",
       "            day_change  three_day  week_change  \n",
       "date                                            \n",
       "2016-01-15   -0.001317  -0.001317    -0.001317  \n",
       "2016-01-14   -0.005772  -0.005772    -0.005772  \n",
       "2016-01-13    0.029305   0.029305     0.029305  \n",
       "2016-01-12   -0.046007  -0.046007    -0.046007  \n",
       "2016-01-11    0.010200   0.010200     0.010200  \n",
       "2016-01-08   -0.014929  -0.014929    -0.014929  \n",
       "2016-01-07   -0.021563  -0.021563    -0.021563  \n",
       "2016-01-06   -0.015477  -0.015477    -0.015477  \n",
       "2016-01-05   -0.019648  -0.019648    -0.019648  \n",
       "2016-01-04    0.000090   0.000090     0.000090  "
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tesla_master.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "tesla_master.to_csv('tesla_master.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When I ran this from the terminal I wrapped everything into one final function which would take in simply the lists of file names, the company name and sensitivity, perform all the intermediate steps and finally save the result down as a well formatted csv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_dataframe_creator(ticker,nyt_files,company_name,twitter_files,sensitivity):\n",
    "    stock_df = stock_formatter_lite(ticker)\n",
    "    nyt_df = nyt_sentiment(nyt_files, company_name, sensitivity)\n",
    "    twitter_df = twitter_sentiment(twitter_files)\n",
    "    master_df = fill_out_sentiments(stock_df,nyt_df,twitter_df)\n",
    "    master_df.to_csv(f'{company_name}_master.csv')\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
